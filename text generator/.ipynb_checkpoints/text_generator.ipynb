{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "tf_gpu",
      "language": "python",
      "name": "tf_gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "text generator.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBcSsTdBIavv"
      },
      "source": [
        "text=open('warpeace_input.txt','r').read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RZjcV7__Iavy"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Flatten,BatchNormalization,Dropout "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A89vVxltIav0",
        "outputId": "fa15ef87-04c0-4b82-85a8-a1700284c895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ufeff\"Well, Prince, so Genoa and Lucca are now just family estates of the\\nBuonapartes. But I warn you, i'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di156Hp2Iav3"
      },
      "source": [
        "chars = list(set(text))\n",
        "VOCAB_SIZE = len(chars)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IWyh8LVIav5",
        "outputId": "eacc9bd2-e30d-4da1-9343-e741679f76c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(chars)}\n",
        "idx2char = np.array(chars)\n",
        "print(char2idx)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'f': 0, 'T': 1, 'c': 2, 'D': 3, 'e': 4, 'F': 5, '5': 6, 'O': 7, ')': 8, 'à': 9, 'P': 10, 'o': 11, 'q': 12, 'a': 13, 'I': 14, 'x': 15, '3': 16, 'K': 17, 'k': 18, 'ê': 19, '\"': 20, 'ä': 21, '=': 22, 'U': 23, 'v': 24, 'N': 25, \"'\": 26, '*': 27, '4': 28, 'm': 29, 'y': 30, 'b': 31, '1': 32, 'V': 33, 'X': 34, 'E': 35, ':': 36, 'r': 37, 'w': 38, 'S': 39, '6': 40, 'R': 41, '(': 42, ',': 43, 'l': 44, 's': 45, 'L': 46, 'u': 47, 'A': 48, 'g': 49, ';': 50, 'z': 51, 'Z': 52, 'd': 53, 't': 54, 'W': 55, 'B': 56, '-': 57, '?': 58, 'n': 59, 'J': 60, 'M': 61, '7': 62, '2': 63, 'h': 64, 'j': 65, '.': 66, '0': 67, '\\n': 68, 'é': 69, 'p': 70, 'i': 71, 'Q': 72, '9': 73, '/': 74, 'G': 75, 'H': 76, 'C': 77, 'Y': 78, '8': 79, ' ': 80, '\\ufeff': 81, '!': 82}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNdrLJJDIav7",
        "outputId": "e8a56236-50a2-42f6-895f-ac37a0714667",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(idx2char)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['f' 'T' 'c' 'D' 'e' 'F' '5' 'O' ')' 'à' 'P' 'o' 'q' 'a' 'I' 'x' '3' 'K'\n",
            " 'k' 'ê' '\"' 'ä' '=' 'U' 'v' 'N' \"'\" '*' '4' 'm' 'y' 'b' '1' 'V' 'X' 'E'\n",
            " ':' 'r' 'w' 'S' '6' 'R' '(' ',' 'l' 's' 'L' 'u' 'A' 'g' ';' 'z' 'Z' 'd'\n",
            " 't' 'W' 'B' '-' '?' 'n' 'J' 'M' '7' '2' 'h' 'j' '.' '0' '\\n' 'é' 'p' 'i'\n",
            " 'Q' '9' '/' 'G' 'H' 'C' 'Y' '8' ' ' '\\ufeff' '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TRxoG3gIav-"
      },
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX73zUMsIawA",
        "outputId": "3b637966-4c93-45a7-cc50-244676530ee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(text_as_int)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[81 20 55 ... 47 45 66]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-myU2zmIawD",
        "outputId": "6aa75b2f-0a19-463b-f6c9-384affa66585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'\\ufeff\"Well, Princ' ---- characters mapped to int ---- > [81 20 55  4 44 44 43 80 10 37 71 59  2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH_qwb2WIawF"
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "no_samples = len(text)/seq_length\n",
        "\n",
        "x=[]\n",
        "y=[]\n",
        "\n",
        "for z in range(int(len(text)/seq_length)):\n",
        "    for i in range(seq_length):\n",
        "        xe=[]\n",
        "        for j in range(seq_length-i-1):\n",
        "            xe.append(char2idx[' '])\n",
        "        for j in range(i+1):\n",
        "            xe.append(text_as_int[z*seq_length+j])\n",
        "        xe=np.array(xe)\n",
        "\n",
        "        x.append(xe)\n",
        "        y.append(text_as_int[(z)*seq_length+i+1])\n",
        " "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lce3nR5XIawH"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(VOCAB_SIZE,256,input_length=seq_length))\n",
        "model.add(LSTM(200,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(200,activation='relu'))\n",
        "model.add(Dense(VOCAB_SIZE,activation='softmax'))\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb0Zbz-kIawJ",
        "outputId": "d2a20b6a-b780-4953-d34e-0b0a493f9824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "temp_y=np.zeros(shape=(len(y),VOCAB_SIZE))\n",
        "x=np.array(x)\n",
        "print(temp_y.shape)\n",
        "print(x.shape)\n",
        "for i in range(len(y)):\n",
        "    temp_y[i][y[i]]=1\n",
        "y=temp_y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3196200, 83)\n",
            "(3196200, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQp9PA7-IawM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.8,test_size=0.02,random_state=42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNx4aIxFIawO",
        "outputId": "c9c038fc-92c7-40ed-eb77-b9b2ed09b2f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2556960, 100)\n",
            "(2556960, 83)\n",
            "(63924, 100)\n",
            "(63924, 83)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UxyCLM8IawR",
        "outputId": "db5e551e-d1f6-4e44-bb7d-45222b4bb391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (x_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[80 80 80 ... 13 45 68]\n",
            " [80 80 80 ... 47 29 70]\n",
            " [80 80 80 ...  4 44  0]\n",
            " ...\n",
            " [80 80 80 ... 80 54 64]\n",
            " [80 80 80 ... 80 71 59]\n",
            " [80 80 80 ... 49 80 53]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIEEQibnIawT"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "checkpoint_path = \"cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "3MAELDW1IawV",
        "outputId": "fe6f5e80-0c3c-411d-c84d-f1c614c87312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=6,batch_size=1000,callbacks=[cp_callback])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "2557/2557 [==============================] - ETA: 0s - loss: 1.8706 - accuracy: 0.4533\n",
            "Epoch 00001: saving model to cp.ckpt\n",
            "2557/2557 [==============================] - 368s 144ms/step - loss: 1.8706 - accuracy: 0.4533 - val_loss: 1.6164 - val_accuracy: 0.5166\n",
            "Epoch 2/6\n",
            "2557/2557 [==============================] - ETA: 0s - loss: 1.5411 - accuracy: 0.5364\n",
            "Epoch 00002: saving model to cp.ckpt\n",
            "2557/2557 [==============================] - 367s 144ms/step - loss: 1.5411 - accuracy: 0.5364 - val_loss: 1.4831 - val_accuracy: 0.5499\n",
            "Epoch 3/6\n",
            "2557/2557 [==============================] - ETA: 0s - loss: 1.4326 - accuracy: 0.5643\n",
            "Epoch 00003: saving model to cp.ckpt\n",
            "2557/2557 [==============================] - 367s 143ms/step - loss: 1.4326 - accuracy: 0.5643 - val_loss: 1.4306 - val_accuracy: 0.5664\n",
            "Epoch 4/6\n",
            "2557/2557 [==============================] - ETA: 0s - loss: 1.3673 - accuracy: 0.5814\n",
            "Epoch 00004: saving model to cp.ckpt\n",
            "2557/2557 [==============================] - 366s 143ms/step - loss: 1.3673 - accuracy: 0.5814 - val_loss: 1.4058 - val_accuracy: 0.5718\n",
            "Epoch 5/6\n",
            "2557/2557 [==============================] - ETA: 0s - loss: 1.3195 - accuracy: 0.5941\n",
            "Epoch 00005: saving model to cp.ckpt\n",
            "2557/2557 [==============================] - 366s 143ms/step - loss: 1.3195 - accuracy: 0.5941 - val_loss: 1.3961 - val_accuracy: 0.5741\n",
            "Epoch 6/6\n",
            "2557/2557 [==============================] - ETA: 0s - loss: 1.2827 - accuracy: 0.6035\n",
            "Epoch 00006: saving model to cp.ckpt\n",
            "2557/2557 [==============================] - 366s 143ms/step - loss: 1.2827 - accuracy: 0.6035 - val_loss: 1.3891 - val_accuracy: 0.5784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6b68f94e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXAyO4txIawX"
      },
      "source": [
        "def predict(txt, word_gen):\n",
        "    inp_len = len(txt) \n",
        "    temp_txt=str()\n",
        "    if inp_len<100:\n",
        "        \n",
        "        for i in range(seq_length-len(txt)):\n",
        "            temp_txt+=' '\n",
        "        temp_txt += txt   \n",
        "    else:\n",
        "        temp_txt = txt[:100]\n",
        "\n",
        "    int_txt=[char2idx[c] for c in temp_txt ]\n",
        "    \n",
        "    int_txt= np.array(int_txt)\n",
        "    int_txt = np.reshape(int_txt,(1,100))\n",
        "\n",
        "    \n",
        "    for i in range(word_gen):\n",
        "        \n",
        "        pred = model.predict(int_txt)\n",
        "        \n",
        "        txt+=idx2char[np.argmax(pred)]\n",
        "        int_txt[0][:99]=int_txt[0][1:]\n",
        "        int_txt[0][99]=np.argmax(pred)\n",
        "\n",
        "        \n",
        "    return txt\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfNBoz1JIawZ",
        "outputId": "c14841fc-f5b5-4b00-97cd-1191f88b4ee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(predict('',400))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the strength of the countess and the count of the countess\n",
            "which had been strained to him. He was now a stretched away and her\n",
            "daughter and he that to the seen that he was a became and there was\n",
            "all the most of the house and were troops to be award and the strange to\n",
            "another and something there was and the count of their faces of the\n",
            "councier was that the care and the counter that he was seen and \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0DiyT9BIawc"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}