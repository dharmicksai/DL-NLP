{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=open('warpeace_input.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM,Flatten,BatchNormalization,Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ï»¿\"Well, Prince, so Genoa and Lucca are now just family estates of the\\nBuonapartes. But I warn you,'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(set(text))\n",
    "VOCAB_SIZE = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'g': 0, 'B': 1, '-': 2, '=': 3, 'N': 4, 'C': 5, 'G': 6, 'h': 7, 'q': 8, '\\xa0': 9, 'D': 10, 'J': 11, 'ª': 12, 'Ã': 13, '.': 14, '?': 15, 'u': 16, \"'\": 17, ';': 18, 'E': 19, '©': 20, 'k': 21, 'd': 22, 'm': 23, 'O': 24, ':': 25, 'T': 26, 'R': 27, 'y': 28, 'H': 29, '1': 30, '8': 31, 't': 32, '!': 33, 'r': 34, '9': 35, '3': 36, 'w': 37, 'V': 38, '\\n': 39, 'Q': 40, 'c': 41, 'A': 42, '/': 43, 'b': 44, 'x': 45, 'U': 46, 'n': 47, 'f': 48, 's': 49, '¤': 50, 'X': 51, '»': 52, 'a': 53, 'l': 54, 'K': 55, '\"': 56, ',': 57, '2': 58, ')': 59, 'W': 60, '5': 61, 'S': 62, '0': 63, ' ': 64, 'Z': 65, 'v': 66, 'ï': 67, '¿': 68, 'z': 69, 'j': 70, '(': 71, '7': 72, 'e': 73, 'F': 74, 'Y': 75, 'o': 76, 'p': 77, 'L': 78, '6': 79, 'I': 80, 'M': 81, 'i': 82, '*': 83, 'P': 84, '4': 85}\n"
     ]
    }
   ],
   "source": [
    "char2idx = {u:i for i, u in enumerate(chars)}\n",
    "idx2char = np.array(chars)\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g' 'B' '-' '=' 'N' 'C' 'G' 'h' 'q' '\\xa0' 'D' 'J' 'ª' 'Ã' '.' '?' 'u'\n",
      " \"'\" ';' 'E' '©' 'k' 'd' 'm' 'O' ':' 'T' 'R' 'y' 'H' '1' '8' 't' '!' 'r'\n",
      " '9' '3' 'w' 'V' '\\n' 'Q' 'c' 'A' '/' 'b' 'x' 'U' 'n' 'f' 's' '¤' 'X' '»'\n",
      " 'a' 'l' 'K' '\"' ',' '2' ')' 'W' '5' 'S' '0' ' ' 'Z' 'v' 'ï' '¿' 'z' 'j'\n",
      " '(' '7' 'e' 'F' 'Y' 'o' 'p' 'L' '6' 'I' 'M' 'i' '*' 'P' '4']\n"
     ]
    }
   ],
   "source": [
    "print(idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67 52 68 ... 16 49 14]\n"
     ]
    }
   ],
   "source": [
    "print(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ï»¿\"Well, Pri' ---- characters mapped to int ---- > [67 52 68 56 60 73 54 54 57 64 84 34 82]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "no_samples = len(text)/seq_length\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for z in range(int(len(text)/seq_length)):\n",
    "    for i in range(seq_length):\n",
    "        xe=[]\n",
    "        for j in range(seq_length-i-1):\n",
    "            xe.append(char2idx[' '])\n",
    "        for j in range(i+1):\n",
    "            xe.append(text_as_int[z*seq_length+j])\n",
    "        xe=np.array(xe)\n",
    "\n",
    "        x.append(xe)\n",
    "        y.append(text_as_int[(z)*seq_length+i+1])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE,256,input_length=seq_length))\n",
    "model.add(LSTM(200,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(200,activation='relu'))\n",
    "model.add(Dense(VOCAB_SIZE,activation='softmax'))\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196200, 86)\n",
      "(3196200, 100)\n"
     ]
    }
   ],
   "source": [
    "temp_y=np.zeros(shape=(len(y),VOCAB_SIZE))\n",
    "x=np.array(x)\n",
    "print(temp_y.shape)\n",
    "print(x.shape)\n",
    "for i in range(len(y)):\n",
    "    temp_y[i][y[i]]=1\n",
    "y=temp_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.2,test_size=0.02,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639240, 100)\n",
      "(639240, 86)\n",
      "(63924, 100)\n",
      "(63924, 86)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64 64 64 ... 16 32 64]\n",
      " [64 64 64 ... 76 34 37]\n",
      " [64 64 64 ... 64  7 73]\n",
      " ...\n",
      " [64 64 64 ... 64 32 49]\n",
      " [64 64 64 ... 73 57 64]\n",
      " [64 64 64 ... 41 54 16]]\n"
     ]
    }
   ],
   "source": [
    "print (x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "checkpoint_path = \"cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "639/640 [============================>.] - ETA: 0s - loss: 2.2507 - accuracy: 0.3625\n",
      "Epoch 00001: saving model to cp.ckpt\n",
      "640/640 [==============================] - 79s 124ms/step - loss: 2.2507 - accuracy: 0.3625 - val_loss: 2.1836 - val_accuracy: 0.4250\n",
      "Epoch 2/6\n",
      "639/640 [============================>.] - ETA: 0s - loss: 1.8133 - accuracy: 0.4641\n",
      "Epoch 00002: saving model to cp.ckpt\n",
      "640/640 [==============================] - 81s 126ms/step - loss: 1.8133 - accuracy: 0.4641 - val_loss: 1.7964 - val_accuracy: 0.4737\n",
      "Epoch 3/6\n",
      "639/640 [============================>.] - ETA: 0s - loss: 1.6388 - accuracy: 0.5094\n",
      "Epoch 00003: saving model to cp.ckpt\n",
      "640/640 [==============================] - 80s 124ms/step - loss: 1.6388 - accuracy: 0.5094 - val_loss: 1.7458 - val_accuracy: 0.4860\n",
      "Epoch 4/6\n",
      "639/640 [============================>.] - ETA: 0s - loss: 1.5187 - accuracy: 0.5397\n",
      "Epoch 00004: saving model to cp.ckpt\n",
      "640/640 [==============================] - 81s 126ms/step - loss: 1.5187 - accuracy: 0.5397 - val_loss: 1.7320 - val_accuracy: 0.4925\n",
      "Epoch 5/6\n",
      "639/640 [============================>.] - ETA: 0s - loss: 1.4221 - accuracy: 0.5646\n",
      "Epoch 00005: saving model to cp.ckpt\n",
      "640/640 [==============================] - 81s 126ms/step - loss: 1.4221 - accuracy: 0.5646 - val_loss: 1.7454 - val_accuracy: 0.4899\n",
      "Epoch 6/6\n",
      "639/640 [============================>.] - ETA: 0s - loss: 1.3372 - accuracy: 0.5877\n",
      "Epoch 00006: saving model to cp.ckpt\n",
      "640/640 [==============================] - 84s 131ms/step - loss: 1.3371 - accuracy: 0.5877 - val_loss: 1.7913 - val_accuracy: 0.4932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21390360488>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=6,batch_size=1000,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(txt, word_gen):\n",
    "    inp_len = len(txt) \n",
    "    temp_txt=str()\n",
    "    if inp_len<100:\n",
    "        \n",
    "        for i in range(seq_length-len(txt)):\n",
    "            temp_txt+=' '\n",
    "        temp_txt += txt   \n",
    "    else:\n",
    "        temp_txt = txt[:100]\n",
    "\n",
    "    int_txt=[char2idx[c] for c in temp_txt ]\n",
    "    \n",
    "    int_txt= np.array(int_txt)\n",
    "    int_txt = np.reshape(int_txt,(1,100))\n",
    "\n",
    "    \n",
    "    for i in range(word_gen):\n",
    "        \n",
    "        pred = model.predict(int_txt)\n",
    "        \n",
    "        txt+=idx2char[np.argmax(pred)]\n",
    "        int_txt[0][:99]=int_txt[0][1:]\n",
    "        int_txt[0][99]=np.argmax(pred)\n",
    "\n",
    "        \n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "war means hate the still of the same to the same which he was\n",
      "seen of the starter and the same was seemed this carnor and the same in\n",
      "the saigh to began to the down and a shoute of the herse his arms all\n",
      "hadked the subjectels of the from and himse went to the count of the\n",
      "councious of the manighturin the seemed the fellows, but the front of\n",
      "his faces and wite to reply defereft the his commander and a maving or \n"
     ]
    }
   ],
   "source": [
    "print(predict('war means hate',400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
